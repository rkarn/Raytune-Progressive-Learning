{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import DEN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import sys\n",
    "\n",
    "np.random.seed(1004)\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"max_iter\", 1000, \"Epoch to train\")\n",
    "flags.DEFINE_float(\"lr\", 0.001, \"Learing rate(init) for train\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch for 1 iteration\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoints\", \"Directory path to save the checkpoints\")\n",
    "flags.DEFINE_integer(\"dims0\", 98, \"Dimensions about input layer\")\n",
    "flags.DEFINE_integer(\"dims1\", 60, \"Dimensions about 1st layer\")\n",
    "flags.DEFINE_integer(\"dims2\", 30, \"Dimensions about 2nd layer\")\n",
    "flags.DEFINE_integer(\"dims3\", 17, \"Dimensions about output layer\")\n",
    "flags.DEFINE_integer(\"n_classes\", 17, 'The number of classes at each task')\n",
    "flags.DEFINE_float(\"l1_lambda\", 0.00001, \"Sparsity for L1\")\n",
    "flags.DEFINE_float(\"l2_lambda\", 0.0001, \"L2 lambda\")\n",
    "flags.DEFINE_float(\"gl_lambda\", 0.001, \"Group Lasso lambda\")\n",
    "flags.DEFINE_float(\"regular_lambda\", 0.05, \"regularization lambda\")\n",
    "flags.DEFINE_integer(\"ex_k\", 200, \"The number of units increased in the expansion processing\")\n",
    "flags.DEFINE_float('loss_thr', 0.01, \"Threshold of dynamic expansion\")\n",
    "flags.DEFINE_float('spl_thr', 0.05, \"Threshold of split and duplication\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "awid_tasks = pickle.load(open('awid_tasks.pkl', \"rb\"))\n",
    "n_tasks = len(awid_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:92: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(14083, 98) (14083, 17)\n",
      "\n",
      "\n",
      "\tTASK 1 TRAINING\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:355: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:361: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:301: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-AWID/DEN/DEN.py:376: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      " [*] iter: 100, val loss: 0.0719, val perf: 0.9560\n",
      " [*] iter: 200, val loss: 0.0321, val perf: 0.9693\n",
      " [*] iter: 300, val loss: 0.0242, val perf: 0.9832\n",
      " [*] iter: 400, val loss: 0.0197, val perf: 0.9903\n",
      " [*] iter: 500, val loss: 0.0147, val perf: 0.9929\n",
      " [*] iter: 600, val loss: 0.0114, val perf: 0.9947\n",
      " [*] iter: 700, val loss: 0.0098, val perf: 0.9952\n",
      " [*] iter: 800, val loss: 0.0090, val perf: 0.9956\n",
      " [*] iter: 900, val loss: 0.0086, val perf: 0.9960\n",
      " [*] iter: 1000, val loss: 0.0081, val perf: 0.9961\n",
      "   [*] Total expansions: [0, 0]\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Task: 1, nn_test_loss: 0.0081, test_perf: 0.9961, sparsity(avg): 0.6533\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.9955\n",
      "   [*] avg_perf: 0.9955\n",
      "(2281, 98) (2281, 17)\n",
      "\n",
      "\n",
      "\tTASK 2 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 99 unit added, (valid, repeated: 1000)\n",
      "   [*] Expanding 1th hidden unit, 16 unit added, (valid, repeated: 1000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 15 / 15\n",
      "   [*] split N in layer2: 12 / 12\n",
      " [*] iter: 100, val loss: 0.0010, val perf: 1.0000\n",
      " [*] iter: 200, val loss: 0.0008, val perf: 1.0000\n",
      " [*] iter: 300, val loss: 0.0007, val perf: 1.0000\n",
      " [*] iter: 400, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 500, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 600, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 700, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 800, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 900, val loss: 0.0005, val perf: 1.0000\n",
      " [*] iter: 1000, val loss: 0.0006, val perf: 1.0000\n",
      "   [*] split, loss: 0.0004, nn_perf: 1.0000(valid) repeated: 1000\n",
      "   [*] Total expansions: [31, 111]\n",
      " [*] hidden 1, shape : [98, 91]\n",
      " [*] hidden 2, shape : [91, 141]\n",
      " [*] Task: 2, nn_test_loss: 0.0006, test_perf: 1.0000, sparsity(avg): 0.5376\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.7155\n",
      " [*] hidden 1, shape : [98, 91]\n",
      " [*] hidden 2, shape : [91, 141]\n",
      " [*] Evaluation, Task:2, test_acc: 1.0000\n",
      "   [*] avg_perf: 0.8577\n",
      "(15035, 98) (15035, 17)\n",
      "\n",
      "\n",
      "\tTASK 3 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 88 unit added, (valid, repeated: 1000)\n",
      "   [*] Expanding 1th hidden unit, 30 unit added, (valid, repeated: 1000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 0 / 0\n",
      "   [*] split N in layer2: 0 / 0\n",
      " [*] iter: 100, val loss: 0.0372, val perf: 0.9716\n",
      " [*] iter: 200, val loss: 0.0307, val perf: 0.9770\n",
      " [*] iter: 300, val loss: 0.0287, val perf: 0.9784\n",
      " [*] iter: 400, val loss: 0.0265, val perf: 0.9826\n",
      " [*] iter: 500, val loss: 0.0254, val perf: 0.9846\n",
      " [*] iter: 600, val loss: 0.0251, val perf: 0.9842\n",
      " [*] iter: 700, val loss: 0.0229, val perf: 0.9869\n",
      " [*] iter: 800, val loss: 0.0240, val perf: 0.9885\n",
      " [*] iter: 900, val loss: 0.0225, val perf: 0.9869\n",
      " [*] iter: 1000, val loss: 0.0222, val perf: 0.9887\n",
      "   [*] split, loss: 0.0225, nn_perf: 0.9887(valid) repeated: 1000\n",
      "   [*] Total expansions: [30, 88]\n",
      " [*] hidden 1, shape : [98, 121]\n",
      " [*] hidden 2, shape : [121, 229]\n",
      " [*] Task: 3, nn_test_loss: 0.0222, test_perf: 0.9887, sparsity(avg): 0.4576\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.5355\n",
      " [*] hidden 1, shape : [98, 91]\n",
      " [*] hidden 2, shape : [91, 141]\n",
      " [*] Evaluation, Task:2, test_acc: 0.5133\n",
      " [*] hidden 1, shape : [98, 121]\n",
      " [*] hidden 2, shape : [121, 229]\n",
      " [*] Evaluation, Task:3, test_acc: 0.9862\n",
      "   [*] avg_perf: 0.6784\n",
      "(16733, 98) (16733, 17)\n",
      "\n",
      "\n",
      "\tTASK 4 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 85 unit added, (valid, repeated: 1000)\n",
      "   [*] Expanding 1th hidden unit, 15 unit added, (valid, repeated: 1000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 0 / 0\n",
      "   [*] split N in layer2: 0 / 0\n",
      " [*] iter: 100, val loss: 0.0096, val perf: 0.9969\n",
      " [*] iter: 200, val loss: 0.0116, val perf: 0.9976\n",
      " [*] iter: 300, val loss: 0.0091, val perf: 0.9977\n",
      " [*] iter: 400, val loss: 0.0085, val perf: 0.9982\n",
      " [*] iter: 500, val loss: 0.0079, val perf: 0.9982\n",
      " [*] iter: 600, val loss: 0.0079, val perf: 0.9982\n",
      " [*] iter: 700, val loss: 0.0077, val perf: 0.9983\n",
      " [*] iter: 800, val loss: 0.0072, val perf: 0.9983\n",
      " [*] iter: 900, val loss: 0.0080, val perf: 0.9984\n",
      " [*] iter: 1000, val loss: 0.0086, val perf: 0.9983\n",
      "   [*] split, loss: 0.0083, nn_perf: 0.9983(valid) repeated: 1000\n",
      "   [*] Total expansions: [15, 85]\n",
      " [*] hidden 1, shape : [98, 136]\n",
      " [*] hidden 2, shape : [136, 314]\n",
      " [*] Task: 4, nn_test_loss: 0.0086, test_perf: 0.9983, sparsity(avg): 0.4180\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.5633\n",
      " [*] hidden 1, shape : [98, 91]\n",
      " [*] hidden 2, shape : [91, 141]\n",
      " [*] Evaluation, Task:2, test_acc: 0.5046\n",
      " [*] hidden 1, shape : [98, 121]\n",
      " [*] hidden 2, shape : [121, 229]\n",
      " [*] Evaluation, Task:3, test_acc: 0.4409\n",
      " [*] hidden 1, shape : [98, 136]\n",
      " [*] hidden 2, shape : [136, 314]\n",
      " [*] Evaluation, Task:4, test_acc: 0.9985\n",
      "   [*] avg_perf: 0.6269\n",
      "(3514, 98) (3514, 17)\n",
      "\n",
      "\n",
      "\tTASK 5 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 72 unit added, (valid, repeated: 1000)\n",
      "   [*] Expanding 1th hidden unit, 17 unit added, (valid, repeated: 1000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 0 / 0\n",
      "   [*] split N in layer2: 0 / 0\n",
      " [*] iter: 100, val loss: 0.0013, val perf: 1.0000\n",
      " [*] iter: 200, val loss: 0.0009, val perf: 1.0000\n",
      " [*] iter: 300, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 400, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 500, val loss: 0.0005, val perf: 1.0000\n",
      " [*] iter: 600, val loss: 0.0006, val perf: 1.0000\n",
      " [*] iter: 700, val loss: 0.0007, val perf: 1.0000\n",
      " [*] iter: 800, val loss: 0.0005, val perf: 1.0000\n",
      " [*] iter: 900, val loss: 0.0005, val perf: 1.0000\n",
      " [*] iter: 1000, val loss: 0.0005, val perf: 1.0000\n",
      "   [*] split, loss: 0.0002, nn_perf: 1.0000(valid) repeated: 1000\n",
      "   [*] Total expansions: [17, 72]\n",
      " [*] hidden 1, shape : [98, 153]\n",
      " [*] hidden 2, shape : [153, 386]\n",
      " [*] Task: 5, nn_test_loss: 0.0005, test_perf: 1.0000, sparsity(avg): 0.3639\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [98, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.6303\n",
      " [*] hidden 1, shape : [98, 91]\n",
      " [*] hidden 2, shape : [91, 141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Evaluation, Task:2, test_acc: 0.5140\n",
      " [*] hidden 1, shape : [98, 121]\n",
      " [*] hidden 2, shape : [121, 229]\n",
      " [*] Evaluation, Task:3, test_acc: 0.5391\n",
      " [*] hidden 1, shape : [98, 136]\n",
      " [*] hidden 2, shape : [136, 314]\n",
      " [*] Evaluation, Task:4, test_acc: 0.5350\n",
      " [*] hidden 1, shape : [98, 153]\n",
      " [*] hidden 2, shape : [153, 386]\n",
      " [*] Evaluation, Task:5, test_acc: 1.0000\n",
      "   [*] avg_perf: 0.6437\n"
     ]
    }
   ],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])\n",
    "\n",
    "import pdb\n",
    "\n",
    "model = DEN.DEN(FLAGS)\n",
    "params = dict()\n",
    "avg_perf = []\n",
    "\n",
    "for m in range(0,n_tasks): #(FLAGS.n_classes):\n",
    "    tasked_input = awid_tasks[m][0]\n",
    "    tasked_output = awid_tasks[m][1]\n",
    "    print (tasked_input.shape,tasked_output.shape)\n",
    "    data = (awid_tasks[m][0],awid_tasks[m][1],awid_tasks[m][2],awid_tasks[m][3],awid_tasks[m][4],awid_tasks[m][5])\n",
    "    model.sess = tf.Session()\n",
    "    print(\"\\n\\n\\tTASK %d TRAINING\\n\"%(m+1))\n",
    "\n",
    "    model.T = model.T+1\n",
    "    model.task_indices.append(m+1)\n",
    "    model.load_params(params, time = 1)\n",
    "    perf, sparsity, expansion = model.add_task(m+1, data)\n",
    "    \n",
    "    params = model.get_params()\n",
    "    #pdb.set_trace()\n",
    "    #analyze_params(params)\n",
    "    model.destroy_graph()\n",
    "    model.sess.close()\n",
    "\n",
    "    model.sess= tf.Session()\n",
    "    print('\\n OVERALL EVALUATION')\n",
    "    model.load_params(params)\n",
    "    temp_perfs = []\n",
    "    for j in range(m+1):\n",
    "        temp_perf = model.predict_perform(j+1, tasked_input, tasked_output)\n",
    "        temp_perfs.append(temp_perf)\n",
    "    avg_perf.append( sum(temp_perfs) / float(m+1) )\n",
    "    print(\"   [*] avg_perf: %.4f\"%avg_perf[m])\n",
    "    model.destroy_graph()\n",
    "    model.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
