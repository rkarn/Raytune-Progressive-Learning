{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import DEN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import sys\n",
    "\n",
    "np.random.seed(1004)\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"max_iter\", 2000, \"Epoch to train\")\n",
    "flags.DEFINE_float(\"lr\", 0.001, \"Learing rate(init) for train\")\n",
    "flags.DEFINE_integer(\"batch_size\", 256, \"The size of batch for 1 iteration\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoints\", \"Directory path to save the checkpoints\")\n",
    "flags.DEFINE_integer(\"dims0\", 43, \"Dimensions about input layer\")\n",
    "flags.DEFINE_integer(\"dims1\", 60, \"Dimensions about 1st layer\")\n",
    "flags.DEFINE_integer(\"dims2\", 30, \"Dimensions about 2nd layer\")\n",
    "flags.DEFINE_integer(\"dims3\", 10, \"Dimensions about output layer\")\n",
    "flags.DEFINE_integer(\"n_classes\", 10, 'The number of classes at each task')\n",
    "flags.DEFINE_float(\"l1_lambda\", 0.00001, \"Sparsity for L1\")\n",
    "flags.DEFINE_float(\"l2_lambda\", 0.0001, \"L2 lambda\")\n",
    "flags.DEFINE_float(\"gl_lambda\", 0.001, \"Group Lasso lambda\")\n",
    "flags.DEFINE_float(\"regular_lambda\", 0.05, \"regularization lambda\")\n",
    "flags.DEFINE_integer(\"ex_k\", 150, \"The number of units increased in the expansion processing\")\n",
    "flags.DEFINE_float('loss_thr', 0.01, \"Threshold of dynamic expansion\")\n",
    "flags.DEFINE_float('spl_thr', 0.05, \"Threshold of split and duplication\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "unsw_tasks = pickle.load(open('unsw_tasks.pkl', \"rb\"))\n",
    "n_tasks = len(unsw_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:91: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:92: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(1260, 43) (1260, 10)\n",
      "\n",
      "\n",
      "\tTASK 1 TRAINING\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:355: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:361: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:301: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/DEN-UNSW/DEN/DEN.py:376: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      " [*] iter: 100, val loss: 0.2998, val perf: 0.5013\n",
      " [*] iter: 200, val loss: 0.1887, val perf: 0.4868\n",
      " [*] iter: 300, val loss: 0.1745, val perf: 0.4681\n",
      " [*] iter: 400, val loss: 0.1713, val perf: 0.4624\n",
      " [*] iter: 500, val loss: 0.1709, val perf: 0.4600\n",
      " [*] iter: 600, val loss: 0.1714, val perf: 0.4591\n",
      " [*] iter: 700, val loss: 0.1723, val perf: 0.4585\n",
      " [*] iter: 800, val loss: 0.1734, val perf: 0.4578\n",
      " [*] iter: 900, val loss: 0.1746, val perf: 0.4571\n",
      " [*] iter: 1000, val loss: 0.1758, val perf: 0.4565\n",
      " [*] iter: 1100, val loss: 0.1770, val perf: 0.4560\n",
      " [*] iter: 1200, val loss: 0.1783, val perf: 0.4555\n",
      " [*] iter: 1300, val loss: 0.1797, val perf: 0.4550\n",
      " [*] iter: 1400, val loss: 0.1810, val perf: 0.4544\n",
      " [*] iter: 1500, val loss: 0.1824, val perf: 0.4536\n",
      " [*] iter: 1600, val loss: 0.1838, val perf: 0.4528\n",
      " [*] iter: 1700, val loss: 0.1852, val perf: 0.4519\n",
      " [*] iter: 1800, val loss: 0.1867, val perf: 0.4510\n",
      " [*] iter: 1900, val loss: 0.1882, val perf: 0.4499\n",
      " [*] iter: 2000, val loss: 0.1897, val perf: 0.4490\n",
      "   [*] Total expansions: [0, 0]\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Task: 1, nn_test_loss: 0.1897, test_perf: 0.4490, sparsity(avg): 0.2141\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.5099\n",
      "   [*] avg_perf: 0.5099\n",
      "(15221, 43) (15221, 10)\n",
      "\n",
      "\n",
      "\tTASK 2 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 61 unit added, (valid, repeated: 2000)\n",
      "   [*] Expanding 1th hidden unit, 87 unit added, (valid, repeated: 2000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 2 / 2\n",
      "   [*] split N in layer2: 5 / 5\n",
      " [*] iter: 100, val loss: 0.1042, val perf: 0.6944\n",
      " [*] iter: 200, val loss: 0.1031, val perf: 0.6970\n",
      " [*] iter: 300, val loss: 0.1031, val perf: 0.6971\n",
      " [*] iter: 400, val loss: 0.1031, val perf: 0.6973\n",
      " [*] iter: 500, val loss: 0.1033, val perf: 0.6978\n",
      " [*] iter: 600, val loss: 0.1031, val perf: 0.6975\n",
      " [*] iter: 700, val loss: 0.1036, val perf: 0.6973\n",
      " [*] iter: 800, val loss: 0.1031, val perf: 0.6978\n",
      " [*] iter: 900, val loss: 0.1031, val perf: 0.6976\n",
      " [*] iter: 1000, val loss: 0.1031, val perf: 0.6976\n",
      " [*] iter: 1100, val loss: 0.1031, val perf: 0.6980\n",
      " [*] iter: 1200, val loss: 0.1031, val perf: 0.6976\n",
      " [*] iter: 1300, val loss: 0.1029, val perf: 0.6982\n",
      " [*] iter: 1400, val loss: 0.1029, val perf: 0.6981\n",
      " [*] iter: 1500, val loss: 0.1032, val perf: 0.6984\n",
      " [*] iter: 1600, val loss: 0.1032, val perf: 0.6982\n",
      " [*] iter: 1700, val loss: 0.1029, val perf: 0.6980\n",
      " [*] iter: 1800, val loss: 0.1029, val perf: 0.6979\n",
      " [*] iter: 1900, val loss: 0.1030, val perf: 0.6982\n",
      " [*] iter: 2000, val loss: 0.1030, val perf: 0.6981\n",
      "   [*] split, loss: 0.1059, nn_perf: 0.6981(valid) repeated: 2000\n",
      "   [*] Total expansions: [89, 66]\n",
      " [*] hidden 1, shape : [43, 149]\n",
      " [*] hidden 2, shape : [149, 96]\n",
      " [*] Task: 2, nn_test_loss: 0.1030, test_perf: 0.6981, sparsity(avg): 0.2292\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.4996\n",
      " [*] hidden 1, shape : [43, 149]\n",
      " [*] hidden 2, shape : [149, 96]\n",
      " [*] Evaluation, Task:2, test_acc: 0.7620\n",
      "   [*] avg_perf: 0.6308\n",
      "(24933, 43) (24933, 10)\n",
      "\n",
      "\n",
      "\tTASK 3 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 79 unit added, (valid, repeated: 2000)\n",
      "   [*] Expanding 1th hidden unit, 19 unit added, (valid, repeated: 2000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 0 / 0\n",
      "   [*] split N in layer2: 1 / 1\n",
      " [*] iter: 100, val loss: 0.0091, val perf: 0.9969\n",
      " [*] iter: 200, val loss: 0.0112, val perf: 0.9969\n",
      " [*] iter: 300, val loss: 0.0126, val perf: 0.9972\n",
      " [*] iter: 400, val loss: 0.0125, val perf: 0.9972\n",
      " [*] iter: 500, val loss: 0.0090, val perf: 0.9972\n",
      " [*] iter: 600, val loss: 0.0090, val perf: 0.9971\n",
      " [*] iter: 700, val loss: 0.0087, val perf: 0.9972\n",
      " [*] iter: 800, val loss: 0.0094, val perf: 0.9970\n",
      " [*] iter: 900, val loss: 0.0113, val perf: 0.9971\n",
      " [*] iter: 1000, val loss: 0.0120, val perf: 0.9972\n",
      " [*] iter: 1100, val loss: 0.0093, val perf: 0.9973\n",
      " [*] iter: 1200, val loss: 0.0096, val perf: 0.9971\n",
      " [*] iter: 1300, val loss: 0.0092, val perf: 0.9972\n",
      " [*] iter: 1400, val loss: 0.0126, val perf: 0.9971\n",
      " [*] iter: 1500, val loss: 0.0102, val perf: 0.9969\n",
      " [*] iter: 1600, val loss: 0.0093, val perf: 0.9972\n",
      " [*] iter: 1700, val loss: 0.0088, val perf: 0.9973\n",
      " [*] iter: 1800, val loss: 0.0108, val perf: 0.9971\n",
      " [*] iter: 1900, val loss: 0.0103, val perf: 0.9970\n",
      " [*] iter: 2000, val loss: 0.0105, val perf: 0.9971\n",
      "   [*] split, loss: 0.0084, nn_perf: 0.9971(valid) repeated: 2000\n",
      "   [*] Total expansions: [19, 80]\n",
      " [*] hidden 1, shape : [43, 168]\n",
      " [*] hidden 2, shape : [168, 176]\n",
      " [*] Task: 3, nn_test_loss: 0.0105, test_perf: 0.9971, sparsity(avg): 0.1699\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.5353\n",
      " [*] hidden 1, shape : [43, 149]\n",
      " [*] hidden 2, shape : [149, 96]\n",
      " [*] Evaluation, Task:2, test_acc: 0.5002\n",
      " [*] hidden 1, shape : [43, 168]\n",
      " [*] hidden 2, shape : [168, 176]\n",
      " [*] Evaluation, Task:3, test_acc: 0.9980\n",
      "   [*] avg_perf: 0.6778\n",
      "(40496, 43) (40496, 10)\n",
      "\n",
      "\n",
      "\tTASK 4 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 82 unit added, (valid, repeated: 2000)\n",
      "   [*] Expanding 1th hidden unit, 42 unit added, (valid, repeated: 2000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 0 / 0\n",
      "   [*] split N in layer2: 0 / 0\n",
      " [*] iter: 100, val loss: 0.0500, val perf: 0.9372\n",
      " [*] iter: 200, val loss: 0.0479, val perf: 0.9375\n",
      " [*] iter: 300, val loss: 0.0540, val perf: 0.9353\n",
      " [*] iter: 400, val loss: 0.0527, val perf: 0.9396\n",
      " [*] iter: 500, val loss: 0.0469, val perf: 0.9403\n",
      " [*] iter: 600, val loss: 0.0488, val perf: 0.9413\n",
      " [*] iter: 700, val loss: 0.0529, val perf: 0.9399\n",
      " [*] iter: 800, val loss: 0.0531, val perf: 0.9396\n",
      " [*] iter: 900, val loss: 0.0439, val perf: 0.9467\n",
      " [*] iter: 1000, val loss: 0.0521, val perf: 0.9428\n",
      " [*] iter: 1100, val loss: 0.0453, val perf: 0.9433\n",
      " [*] iter: 1200, val loss: 0.0518, val perf: 0.9439\n",
      " [*] iter: 1300, val loss: 0.0478, val perf: 0.9430\n",
      " [*] iter: 1400, val loss: 0.0526, val perf: 0.9416\n",
      " [*] iter: 1500, val loss: 0.0443, val perf: 0.9468\n",
      " [*] iter: 1600, val loss: 0.0440, val perf: 0.9483\n",
      " [*] iter: 1700, val loss: 0.0472, val perf: 0.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] iter: 1800, val loss: 0.0455, val perf: 0.9478\n",
      " [*] iter: 1900, val loss: 0.0439, val perf: 0.9477\n",
      " [*] iter: 2000, val loss: 0.0453, val perf: 0.9448\n",
      "   [*] split, loss: 0.0083, nn_perf: 0.9448(valid) repeated: 2000\n",
      "   [*] Total expansions: [42, 82]\n",
      " [*] hidden 1, shape : [43, 210]\n",
      " [*] hidden 2, shape : [210, 258]\n",
      " [*] Task: 4, nn_test_loss: 0.0453, test_perf: 0.9448, sparsity(avg): 0.1808\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.5099\n",
      " [*] hidden 1, shape : [43, 149]\n",
      " [*] hidden 2, shape : [149, 96]\n",
      " [*] Evaluation, Task:2, test_acc: 0.5000\n",
      " [*] hidden 1, shape : [43, 168]\n",
      " [*] hidden 2, shape : [168, 176]\n",
      " [*] Evaluation, Task:3, test_acc: 0.5000\n",
      " [*] hidden 1, shape : [43, 210]\n",
      " [*] hidden 2, shape : [210, 258]\n",
      " [*] Evaluation, Task:4, test_acc: 0.9922\n",
      "   [*] avg_perf: 0.6255\n",
      "(422, 43) (422, 10)\n",
      "\n",
      "\n",
      "\tTASK 5 TRAINING\n",
      "\n",
      " [*] Selective retraining\n",
      " [*] Network expansion (training)\n",
      "   [*] Expanding 2th hidden unit, 0 unit added, (valid, repeated: 2000)\n",
      "   [*] Expanding 1th hidden unit, 0 unit added, (valid, repeated: 2000)\n",
      " [*] Split & Duplication\n",
      "   [*] split N in layer1: 150 / 177\n",
      "   [*] split N in layer2: 150 / 222\n",
      " [*] iter: 100, val loss: 0.0355, val perf: 0.9140\n",
      " [*] iter: 200, val loss: 0.0370, val perf: 0.9138\n",
      " [*] iter: 300, val loss: 0.0452, val perf: 0.9130\n",
      " [*] iter: 400, val loss: 0.0586, val perf: 0.9136\n",
      " [*] iter: 500, val loss: 0.0720, val perf: 0.9169\n",
      " [*] iter: 600, val loss: 0.0829, val perf: 0.9216\n",
      " [*] iter: 700, val loss: 0.0910, val perf: 0.9246\n",
      " [*] iter: 800, val loss: 0.0976, val perf: 0.9276\n",
      " [*] iter: 900, val loss: 0.1032, val perf: 0.9303\n",
      " [*] iter: 1000, val loss: 0.1081, val perf: 0.9322\n",
      " [*] iter: 1100, val loss: 0.1126, val perf: 0.9339\n",
      " [*] iter: 1200, val loss: 0.1168, val perf: 0.9355\n",
      " [*] iter: 1300, val loss: 0.1206, val perf: 0.9363\n",
      " [*] iter: 1400, val loss: 0.1243, val perf: 0.9369\n",
      " [*] iter: 1500, val loss: 0.1281, val perf: 0.9373\n",
      " [*] iter: 1600, val loss: 0.1321, val perf: 0.9375\n",
      " [*] iter: 1700, val loss: 0.1359, val perf: 0.9375\n",
      " [*] iter: 1800, val loss: 0.1396, val perf: 0.9375\n",
      " [*] iter: 1900, val loss: 0.1432, val perf: 0.9374\n",
      " [*] iter: 2000, val loss: 0.1468, val perf: 0.9373\n",
      "   [*] split, loss: 0.1447, nn_perf: 0.9373(valid) repeated: 2000\n",
      "   [*] Total expansions: [150, 150]\n",
      " [*] hidden 1, shape : [43, 360]\n",
      " [*] hidden 2, shape : [360, 408]\n",
      " [*] Task: 5, nn_test_loss: 0.1468, test_perf: 0.9373, sparsity(avg): 0.7600\n",
      "\n",
      " OVERALL EVALUATION\n",
      " [*] hidden 1, shape : [43, 60]\n",
      " [*] hidden 2, shape : [60, 30]\n",
      " [*] Evaluation, Task:1, test_acc: 0.4979\n",
      " [*] hidden 1, shape : [43, 149]\n",
      " [*] hidden 2, shape : [149, 96]\n",
      " [*] Evaluation, Task:2, test_acc: 0.5000\n",
      " [*] hidden 1, shape : [43, 168]\n",
      " [*] hidden 2, shape : [168, 176]\n",
      " [*] Evaluation, Task:3, test_acc: 0.5001\n",
      " [*] hidden 1, shape : [43, 210]\n",
      " [*] hidden 2, shape : [210, 258]\n",
      " [*] Evaluation, Task:4, test_acc: 0.5000\n",
      " [*] hidden 1, shape : [43, 360]\n",
      " [*] hidden 2, shape : [360, 408]\n",
      " [*] Evaluation, Task:5, test_acc: 0.8894\n",
      "   [*] avg_perf: 0.5775\n"
     ]
    }
   ],
   "source": [
    "remaining_args = FLAGS([sys.argv[0]] + [flag for flag in sys.argv if flag.startswith(\"--\")])\n",
    "assert(remaining_args == [sys.argv[0]])\n",
    "\n",
    "import pdb\n",
    "\n",
    "model = DEN.DEN(FLAGS)\n",
    "params = dict()\n",
    "avg_perf = []\n",
    "\n",
    "for m in range(0,n_tasks): #(FLAGS.n_classes):\n",
    "    tasked_input = unsw_tasks[m][0]\n",
    "    tasked_output = unsw_tasks[m][1]\n",
    "    print (tasked_input.shape,tasked_output.shape)\n",
    "    data = (unsw_tasks[m][0],unsw_tasks[m][1],unsw_tasks[m][2],unsw_tasks[m][3],unsw_tasks[m][4],unsw_tasks[m][5])\n",
    "    model.sess = tf.Session()\n",
    "    print(\"\\n\\n\\tTASK %d TRAINING\\n\"%(m+1))\n",
    "\n",
    "    model.T = model.T+1\n",
    "    model.task_indices.append(m+1)\n",
    "    model.load_params(params, time = 1)\n",
    "    perf, sparsity, expansion = model.add_task(m+1, data)\n",
    "    \n",
    "    params = model.get_params()\n",
    "    #pdb.set_trace()\n",
    "    #analyze_params(params)\n",
    "    model.destroy_graph()\n",
    "    model.sess.close()\n",
    "\n",
    "    model.sess= tf.Session()\n",
    "    print('\\n OVERALL EVALUATION')\n",
    "    model.load_params(params)\n",
    "    temp_perfs = []\n",
    "    for j in range(m+1):\n",
    "        temp_perf = model.predict_perform(j+1, tasked_input, tasked_output)\n",
    "        temp_perfs.append(temp_perf)\n",
    "    avg_perf.append( sum(temp_perfs) / float(m+1) )\n",
    "    print(\"   [*] avg_perf: %.4f\"%avg_perf[m])\n",
    "    model.destroy_graph()\n",
    "    model.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
